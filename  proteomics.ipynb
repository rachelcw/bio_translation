{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyensembl\n",
    "import numpy as np\n",
    "from types import MappingProxyType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mut_file=open(\"/home/ls/rachelcw/projects/salmon/transcriptome_mut.fa\",\"r\")\n",
    "unmut_file=open(\"/home/ls/rachelcw/projects/salmon/transcriptome_unmut.fa\",\"r\")\n",
    "head_seq_dict={}\n",
    "for line in unmut_file:\n",
    "    line=line.strip()\n",
    "    if line.startswith(\">\"):\n",
    "        head=line\n",
    "    else: # line = seq\n",
    "        if head not in head_seq_dict.keys():\n",
    "            head_seq_dict[head]=line\n",
    "for line in mut_file:\n",
    "    line=line.strip()\n",
    "    head=''\n",
    "    if line not in head_seq_dict.keys():\n",
    "        if line.startswith(\">\"):\n",
    "            head=line\n",
    "        else: # line = seq\n",
    "            head_seq_dict[head]=line\n",
    "mut_file.close()\n",
    "unmut_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata=pd.read_csv(\"/data01/private/projects/splicing_cll/results/proteomics/analysis.20230724/results/metadata_cll_sf3b1_proteomics.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata=pd.read_csv(\"/data01/private/projects/splicing_cll/results/proteomics/analysis.20230713/results/metadata_cll_sf3b1_proteomics.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "known             109\n",
       "novel_5p           65\n",
       "novel_both          8\n",
       "novel_3p            4\n",
       "novel_junction      2\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.loc[metadata['strand'] == '-', 'category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupfile=pd.read_csv(\"/home/ls/rachelcw/projects/LEAFCUTTER/DS/DS.five_percent/groups_file.analysis.20230108/groups_file_a4.txt\",sep=\"\\t\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to get the genes by individual.\n",
    "def get_gene_list(genelist):\n",
    "    data_gene_list=[]\n",
    "    for value in genelist:  \n",
    "        value = value.split(',')\n",
    "        data_gene_list.extend(value)\n",
    "    \n",
    "    return list(set(data_gene_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyensembl.sequence_data:Loaded sequence dictionary from /private1/private/resources/Homo_sapiens_assembly19.fasta.pickle\n"
     ]
    }
   ],
   "source": [
    "genome = pyensembl.Genome(\n",
    "    reference_name='GRCh37',\n",
    "    annotation_name='my_genome_lab',\n",
    "    gtf_path_or_url='/home/ls/rachelcw/projects/protein_coding.gtf',\n",
    "    transcript_fasta_paths_or_urls= '/private1/private/resources/Homo_sapiens_assembly19.fasta')\n",
    "genome.index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************************************************\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadata table preparation- Differential splicing (DS) events (intron-defined), considered for output to following peptide files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutated VS unmutated SF3B1 - group 2 - M+U CLL\n",
    "cluster_MU = pd.read_csv('~/projects/LEAFCUTTER/DS/DS.five_percent/analysis.20230512/fdr0.05/filtered.a2.20230512_cluster_significance.txt',sep=\" \",usecols=[\"cluster\",\"p\",\"p.adjust\",\"genes\"])\n",
    "cluster_MU.rename(columns={\"p\":\"p_mu\",\"p.adjust\":\"p.adjust_mu\"},inplace=True)\n",
    "effect_size_MU=pd.read_csv('~/projects/LEAFCUTTER/DS/DS.five_percent/analysis.20230512/fdr0.05/filtered.a2.20230512_effect_sizes.txt',sep=\" \",usecols=[\"intron\",\"unmut\",\"mut\",\"deltapsi\"])\n",
    "effect_size_MU=effect_size_MU[np.abs(effect_size_MU[\"deltapsi\"])>0.1]\n",
    "effect_size_MU.rename(columns={\"unmut\":\"unmutPSI_mu\",\"mut\":\"mutPSI_mu\",\"deltapsi\":\"dPSI_mu\"},inplace=True)\n",
    "# mutated VS unmutated SF3B1 - group 6 - U CLL\n",
    "cluster_U= pd.read_csv('~/projects/LEAFCUTTER/DS/DS.five_percent/analysis.20230512/fdr0.05/filtered.a6.20230512_cluster_significance.txt',sep=\" \",usecols=[\"cluster\",\"p\",\"p.adjust\",\"genes\"])\n",
    "cluster_U.rename(columns={\"p\":\"p_u\",\"p.adjust\":\"p.adjust_u\"}, inplace=True)\n",
    "effect_size_U=pd.read_csv('~/projects/LEAFCUTTER/DS/DS.five_percent/analysis.20230512/fdr0.05/filtered.a6.20230512_effect_sizes.txt',sep=\" \",usecols=[\"intron\",\"unmut\",\"mut\",\"deltapsi\"])\n",
    "effect_size_U=effect_size_U[np.abs(effect_size_U[\"deltapsi\"])>0.1]\n",
    "effect_size_U.rename(columns={\"unmut\":\"unmutPSI_u\",\"mut\":\"mutPSI_u\",\"deltapsi\":\"dPSI_u\"},inplace=True)\n",
    "# mutated VS unmutated SF3B1 - group 4 - M CLL\n",
    "cluster_M= pd.read_csv('~/projects/LEAFCUTTER/DS/DS.five_percent/analysis.20230512/fdr0.05/filtered.a4.20230512_cluster_significance.txt',sep=\" \",usecols=[\"cluster\",\"p\",\"p.adjust\",\"genes\"])\n",
    "cluster_M.rename(columns={\"p\":\"p_m\",\"p.adjust\":\"p.adjust_m\"}, inplace=True)\n",
    "effect_size_M=pd.read_csv('~/projects/LEAFCUTTER/DS/DS.five_percent/analysis.20230512/fdr0.05/filtered.a4.20230512_effect_sizes.txt',sep=\" \", usecols=[\"intron\",\"unmut\",\"mut\",\"deltapsi\"])\n",
    "effect_size_M=effect_size_M[np.abs(effect_size_M[\"deltapsi\"])>0.1]\n",
    "effect_size_M.rename(columns={\"unmut\":\"unmutPSI_m\",\"mut\":\"mutPSI_m\",\"deltapsi\":\"dPSI_m\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table for each junction and its corresponding gene and PSI,deltaPSI,pvalue,p.adjust from each dataset\n",
    "cluster_merge=pd.merge(cluster_MU,cluster_U,on=[\"cluster\",\"genes\"],how=\"outer\").merge(cluster_M,on=[\"cluster\",\"genes\"],how=\"outer\")\n",
    "cluster_merge=cluster_merge[['cluster','genes','p.adjust_mu','p.adjust_u','p.adjust_m','p_mu','p_u','p_m']]\n",
    "\n",
    "effect_size_merge=pd.merge(effect_size_MU,effect_size_U,on=[\"intron\"],how=\"outer\").merge(effect_size_M,on=[\"intron\"],how=\"outer\")\n",
    "effect_size_merge=effect_size_merge[['intron','unmutPSI_mu','mutPSI_mu','dPSI_mu','unmutPSI_u','mutPSI_u','dPSI_u','unmutPSI_m','mutPSI_m','dPSI_m']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_size_merge[[\"intron\",\"cluster\"]]=effect_size_merge[\"intron\"].str.rsplit(\":\",1,expand=True)\n",
    "cluster_merge[[\"chr\",\"cluster\"]]=cluster_merge[\"cluster\"].str.split(\":\",expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=effect_size_merge.merge(cluster_merge,on=[\"cluster\"],how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table['junction'] = table['intron'].str.cat(table['cluster'].str.replace(r'clu_\\d*_','',regex=True), sep=':')\n",
    "table['junction'] = table['intron'].str.cat(table['cluster'], sep=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_count=pd.read_csv(\"/home/ls/rachelcw/projects/LEAFCUTTER/lc_20230512/lc_20230512_perind_numers.counts.gz\",compression='gzip',sep=\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum=read_count.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "table['junction_no_chr']=table['junction'].str.replace('chr','',)\n",
    "table['read_count']=table['junction_no_chr'].map(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['intron', 'unmutPSI_mu', 'mutPSI_mu', 'dPSI_mu', 'unmutPSI_u',\n",
       "       'mutPSI_u', 'dPSI_u', 'unmutPSI_m', 'mutPSI_m', 'dPSI_m', 'cluster',\n",
       "       'genes', 'p.adjust_mu', 'p.adjust_u', 'p.adjust_m', 'p_mu', 'p_u',\n",
       "       'p_m', 'chr', 'junction', 'junction_no_chr', 'read_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.drop(columns=['intron','cluster','chr','junction_no_chr'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=table[['junction','genes','read_count','unmutPSI_mu','mutPSI_mu','dPSI_mu','unmutPSI_u','mutPSI_u','dPSI_u','unmutPSI_m','mutPSI_m','dPSI_m','p.adjust_mu','p.adjust_u','p.adjust_m','p_mu','p_u','p_m']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "table[[\"chr\",\"start\",\"end\",\"cluster\"]]=table[\"junction\"].str.split(\":\",expand=True)\n",
    "table[\"start\"]=table[\"start\"].astype(int)\n",
    "table[\"end\"]=table[\"end\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=table.copy()\n",
    "data.dropna(subset=[\"genes\"],axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ls/rachelcw/miniconda3/envs/bio/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3552: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "all_intron=pd.read_csv(\"/data01/private/resources/leafcutter_annot/leafcutter_annot_all_introns.bed.gz\",sep=\"\\t\",header=None,compression=\"gzip\",usecols=[0,1,2,3,4,5,6,8],names=[\"chr\",\"start\",\"end\",\"gene\",\"gene_id\",\"strand\",\"transcript_id\",\"annotation\"])\n",
    "protein_intron=all_intron[all_intron[\"annotation\"]==\"protein_coding\"]\n",
    "data_gene_list=get_gene_list(data['genes'].unique())\n",
    "intron_in_data=protein_intron[protein_intron[\"gene\"].isin(data_gene_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['cluster','strand']]=data['cluster'].str.rsplit('_', expand=True, n=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate rows based on comma-separated values- genes\n",
    "new_rows = []\n",
    "for index, row in data.iterrows():\n",
    "    values = row['genes'].split(',')\n",
    "    if len(values) > 1:\n",
    "        for i, value in enumerate(values):\n",
    "            new_row = row.copy()\n",
    "            new_row['genes'] = value\n",
    "            new_rows.append(new_row)\n",
    "    else:\n",
    "        new_rows.append(row)\n",
    "\n",
    "# Create updated DataFrame\n",
    "data = pd.DataFrame(new_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_dict={key: value for key, value in zip(protein_intron[\"gene\"],protein_intron[\"gene_id\"])}\n",
    "data[\"gene_id\"]=data[\"genes\"].map(gene_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leafcutter defines 5p as lower coordinate and 3p as higher coordinate - so when we deal with reverse strand, we need to switch the 5p and 3p\n",
    "data[\"category\"]=pd.NA\n",
    "data[\"transcript_id\"]=pd.NA\n",
    "\n",
    "for index,row in data.iterrows():\n",
    "    # known intron\n",
    "    if ((intron_in_data[\"start\"]==row[\"start\"]).any()&(intron_in_data[\"end\"]==row[\"end\"]).any()):\n",
    "        start_trans_id = intron_in_data.loc[intron_in_data['start'] == row[\"start\"], 'transcript_id']\n",
    "        end_trans_id = intron_in_data.loc[intron_in_data['end'] == row[\"end\"], 'transcript_id']\n",
    "        data.loc[index,\"category\"]=\"known\"\n",
    "        trans_id = ','.join(pd.concat([start_trans_id, end_trans_id], ignore_index=True).unique())\n",
    "        data.loc[index,\"transcript_id\"]=trans_id\n",
    "        # trans_id=intron_in_data.loc[(intron_in_data['start'] == row[\"start\"]) & (intron_in_data['transcript_id'].isin(intron_in_data.loc[intron_in_data['end'] == row[\"end\"], 'transcript_id'])), 'transcript_id'] \n",
    "    # forward strand: novel_3p = start of intron is known\n",
    "    # reverse strand: novel_5p = start of intron is known\n",
    "    elif (intron_in_data[\"start\"]==row[\"start\"]).any():\n",
    "        if row[\"strand\"]==\"+\":\n",
    "            data.loc[index,\"category\"]=\"novel_3p\"\n",
    "        else:\n",
    "            data.loc[index,\"category\"]=\"novel_5p\"\n",
    "        trans_id=intron_in_data.loc[intron_in_data[\"start\"]==row[\"start\"],\"transcript_id\"]\n",
    "        data.loc[index,\"transcript_id\"]=','.join(trans_id)\n",
    "    # forward strand: novel_5p = end of intron is known\n",
    "    # reverse strand: novel_3p = end of intron is known\n",
    "    elif (intron_in_data[\"end\"]==row[\"end\"]).any():\n",
    "        if row[\"strand\"]==\"+\":\n",
    "            data.loc[index,\"category\"]=\"novel_5p\"\n",
    "        else:\n",
    "            data.loc[index,\"category\"]=\"novel_3p\"\n",
    "        trans_id=intron_in_data.loc[intron_in_data[\"end\"]==row[\"end\"],\"transcript_id\"]\n",
    "        data.loc[index,\"transcript_id\"]=','.join(trans_id)\n",
    "    # novel_both = both ends of intron are novel\n",
    "    else:\n",
    "        data.loc[index,\"category\"]=\"novel_both\"\n",
    "        transcript_of_intron=genome.transcript_ids_at_locus(contig=row.chr.replace(\"chr\",\"\"),position=row.end) \n",
    "        mask = protein_intron['transcript_id'].isin(transcript_of_intron)\n",
    "        # # Get the transcript IDs that are present\n",
    "        present_transcript_ids = protein_intron.loc[mask, 'transcript_id'].unique()\n",
    "        for transcript in present_transcript_ids:\n",
    "            gene_name=genome.gene_name_of_transcript_id(transcript)\n",
    "            if gene_name!=row[\"genes\"]:\n",
    "                present_transcript_ids=np.delete(present_transcript_ids, np.where(present_transcript_ids == transcript))\n",
    "        if len(present_transcript_ids)>0:\n",
    "            data.loc[index,\"transcript_id\"]=','.join(present_transcript_ids)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ls/rachelcw/miniconda3/envs/bio/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/home/ls/rachelcw/miniconda3/envs/bio/lib/python3.7/site-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "# cluster known junction to known or novel junction( cassette exon )\n",
    "# the junction that merges between two transcripts was not taken into account in the analysis\n",
    "start_end_intron=[tuple(x) for x in intron_in_data[[\"start\",\"end\"]].values]\n",
    "known_intron=data[data[\"category\"]==\"known\"]\n",
    "ce=[tuple(x) for x in known_intron[[\"start\",\"end\"]].values if tuple(x) not in start_end_intron]\n",
    "ce_intron=known_intron.loc[known_intron[[\"start\",\"end\"]].apply(tuple,1).isin(ce)]\n",
    "ce_intron[\"category\"]=\"novel_junction\"\n",
    "for index,row in ce_intron.iterrows():\n",
    "    start=intron_in_data.loc[intron_in_data[\"start\"]==row[\"start\"],\"transcript_id\"].values\n",
    "    end=intron_in_data.loc[intron_in_data[\"end\"]==row[\"end\"],\"transcript_id\"].values\n",
    "    # get only the not shared transcript\n",
    "    only_start = [x for x in start if x not in end]  \n",
    "    only_end = [x for x in end if x not in start]\n",
    "    if len(only_start)>0 and len(only_end)>0:\n",
    "        # ce_intron.loc[index,\"transcript_id\"]=','.join(only_start)+'-'+','.join(only_end)\n",
    "        ce_intron.loc[index,\"category\"]=\"two_transcripts\"\n",
    "mapping=dict(zip(ce_intron[\"junction\"],ce_intron[\"category\"]))\n",
    "data[\"category\"]=data[\"junction\"].map(mapping).fillna(data[\"category\"])\n",
    "data.dropna(subset=[\"transcript_id\"],axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=[\"gene_id\"],axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[data[\"category\"]!=\"two_transcripts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"/data01/private/projects/splicing_cll/results/proteomics/analysis.20230724/results/metadata_cll_sf3b1_proteomics.tsv\",sep=\"\\t\",index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation\n",
    "\n",
    "* merge datasets from leafcutter results- M-U-CLL, M-CLL and U-CLL\n",
    "* filter out delta psi values < 0.1\n",
    "* split into mutated(deltaPSI < 0) vs unmutated (deltaPSI > 0) SF3B1\n",
    "* cluster the junction into 4 categories- 1) \"know\", 2) \"start\" 3) \"end\" 4) \"novel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutated VS unmutated SF3B1 - group 2 - M+U CLL\n",
    "cluster_MU = pd.read_csv('~/projects/LEAFCUTTER/DS/DS.five_percent/analysis.20230512/fdr0.05/filtered.a2.20230512_cluster_significance.txt',sep=\" \",usecols=[\"cluster\",\"p\",\"p.adjust\",\"genes\"])\n",
    "effect_size_MU=pd.read_csv('~/projects/LEAFCUTTER/DS/DS.five_percent/analysis.20230512/fdr0.05/filtered.a2.20230512_effect_sizes.txt',sep=\" \",usecols=[\"intron\",\"unmut\",\"mut\",\"deltapsi\"])\n",
    "# mutated VS unmutated SF3B1 - group 6 - U CLL\n",
    "cluster_U= pd.read_csv('~/projects/LEAFCUTTER/DS/DS.five_percent/analysis.20230512/fdr0.05/filtered.a6.20230512_cluster_significance.txt',sep=\" \",usecols=[\"cluster\",\"p\",\"p.adjust\",\"genes\"])\n",
    "effect_size_U=pd.read_csv('~/projects/LEAFCUTTER/DS/DS.five_percent/analysis.20230512/fdr0.05/filtered.a6.20230512_effect_sizes.txt',sep=\" \",usecols=[\"intron\",\"unmut\",\"mut\",\"deltapsi\"])\n",
    "# mutated VS unmutated SF3B1 - group 4 - M CLL\n",
    "cluster_M= pd.read_csv('~/projects/LEAFCUTTER/DS/DS.five_percent/analysis.20230512/fdr0.05/filtered.a4.20230512_cluster_significance.txt',sep=\" \",usecols=[\"cluster\",\"p\",\"p.adjust\",\"genes\"])\n",
    "effect_size_M=pd.read_csv('~/projects/LEAFCUTTER/DS/DS.five_percent/analysis.20230512/fdr0.05/filtered.a4.20230512_effect_sizes.txt',sep=\" \", usecols=[\"intron\",\"unmut\",\"mut\",\"deltapsi\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster=pd.concat([cluster_MU,cluster_U,cluster_M],ignore_index=True)\n",
    "effect_size=pd.concat([effect_size_MU,effect_size_U,effect_size_M],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold of 10% for deltaPSI\n",
    "effect_size=effect_size[np.abs(effect_size[\"deltapsi\"])>0.1]\n",
    "# filtered out junction mut(psi) > unmut(psi) --> delta psi < 0\n",
    "# mutated=effect_size[effect_size[\"deltapsi\"]<0]\n",
    "unmutated=effect_size[effect_size[\"deltapsi\"]>0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(206,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ls/rachelcw/miniconda3/envs/bio_sns/lib/python3.7/site-packages/pandas/core/frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "/home/ls/rachelcw/miniconda3/envs/bio_sns/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/ls/rachelcw/miniconda3/envs/bio_sns/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "unmutated[[\"chr\",\"start\",\"end\",\"cluster\"]]=unmutated[\"intron\"].str.split(\":\",expand=True)\n",
    "unmutated[\"start\"]=unmutated[\"start\"].astype(int)\n",
    "unmutated[\"end\"]=unmutated[\"end\"].astype(int)\n",
    "print(unmutated[\"cluster\"].unique().shape)\n",
    "cluster[[\"chr\",\"cluster\"]]=cluster[\"cluster\"].str.split(\":\",expand=True)\n",
    "unmutated=unmutated.merge(cluster,on=[\"chr\",\"cluster\"],how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutated[[\"chr\",\"start\",\"end\",\"cluster\"]]=mutated[\"intron\"].str.split(\":\",expand=True)\n",
    "# mutated[\"start\"]=mutated[\"start\"].astype(int)\n",
    "# mutated[\"end\"]=mutated[\"end\"].astype(int)\n",
    "# print(mutated[\"cluster\"].unique().shape)\n",
    "# cluster[[\"chr\",\"cluster\"]]=cluster[\"cluster\"].str.split(\":\",expand=True)\n",
    "# mutated=mutated.merge(cluster,on=[\"chr\",\"cluster\"],how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the junction with the highest delta psi\n",
    "\n",
    "# mutated.sort_values(by=[\"deltapsi\"],inplace=True)\n",
    "# mutated.drop_duplicates(subset=[\"intron\"],keep='first',inplace=True)\n",
    "unmutated.sort_values(by=[\"deltapsi\"],inplace=True,ascending=False)\n",
    "unmutated.drop_duplicates(subset=[\"intron\"],keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=mutated.filter(items=[\"intron\",\"chr\",\"start\",\"end\",\"genes\",\"cluster\",\"p.adjust\",\"deltapsi\"])\n",
    "data=unmutated.filter(items=[\"intron\",\"chr\",\"start\",\"end\",\"genes\",\"cluster\",\"p.adjust\",\"deltapsi\"])\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ls/rachelcw/miniconda3/envs/bio_sns/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3552: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "all_intron=pd.read_csv(\"/data01/private/resources/leafcutter_annot/leafcutter_annot_all_introns.bed.gz\",sep=\"\\t\",header=None,compression=\"gzip\",usecols=[0,1,2,3,4,5,6,8],names=[\"chr\",\"start\",\"end\",\"gene\",\"gene_id\",\"strand\",\"transcript_id\",\"annotation\"])\n",
    "protein_intron=all_intron[all_intron[\"annotation\"]==\"protein_coding\"]\n",
    "data_gene_list=get_gene_list(data['genes'].unique())\n",
    "intron_in_data=protein_intron[protein_intron[\"gene\"].isin(data_gene_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['cluster','strand']]=data['cluster'].str.rsplit('_', expand=True, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate rows based on comma-separated values- genes\n",
    "new_rows = []\n",
    "for index, row in data.iterrows():\n",
    "    values = row['genes'].split(',')\n",
    "    if len(values) > 1:\n",
    "        for i, value in enumerate(values):\n",
    "            new_row = row.copy()\n",
    "            new_row['genes'] = value\n",
    "            new_rows.append(new_row)\n",
    "    else:\n",
    "        new_rows.append(row)\n",
    "\n",
    "# Create updated DataFrame\n",
    "data = pd.DataFrame(new_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_dict={key: value for key, value in zip(protein_intron[\"gene\"],protein_intron[\"gene_id\"])}\n",
    "data[\"gene_id\"]=data[\"genes\"].map(gene_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intron      0\n",
       "chr         0\n",
       "start       0\n",
       "end         0\n",
       "genes       0\n",
       "cluster     0\n",
       "p.adjust    0\n",
       "deltapsi    0\n",
       "strand      0\n",
       "gene_id     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop gene that arn't \"protein coding\" \n",
    "data.dropna(axis=0,inplace=True)\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"known\"]=pd.NA\n",
    "data[\"transcript_id\"]=pd.NA\n",
    "# for gene in data_gene_list:\n",
    "    # data_gene=data[data[\"genes\"].str.contains(gene)]\n",
    "    # intron_gene=intron_in_data[intron_in_data[\"gene\"].str.contains(gene)]\n",
    "for index,row in data.iterrows():\n",
    "    if ((intron_in_data[\"start\"]==row[\"start\"]).any()&(intron_in_data[\"end\"]==row[\"end\"]).any()):\n",
    "        start_trans_id = intron_in_data.loc[intron_in_data['start'] == row[\"start\"], 'transcript_id']\n",
    "        end_trans_id = intron_in_data.loc[intron_in_data['end'] == row[\"end\"], 'transcript_id']\n",
    "        # if intron_in_data.loc[(intron_in_data['start'] == row[\"start\"])&(intron_in_data['end'] == row[\"end\"])].empty:\n",
    "        #     data.loc[index,\"known\"]=\"two_transcripts\"\n",
    "        #     trans_id = ''.join(start_trans_id.values+'-'+end_trans_id.values)\n",
    "        # else:\n",
    "        data.loc[index,\"known\"]=\"known\"\n",
    "        trans_id = ','.join(pd.concat([start_trans_id, end_trans_id], ignore_index=True).unique())\n",
    "        data.loc[index,\"transcript_id\"]=trans_id\n",
    "        # trans_id=intron_in_data.loc[(intron_in_data['start'] == row[\"start\"]) & (intron_in_data['transcript_id'].isin(intron_in_data.loc[intron_in_data['end'] == row[\"end\"], 'transcript_id'])), 'transcript_id'] \n",
    "    elif (intron_in_data[\"start\"]==row[\"start\"]).any():\n",
    "        data.loc[index,\"known\"]=\"start\"\n",
    "        trans_id=intron_in_data.loc[intron_in_data[\"start\"]==row[\"start\"],\"transcript_id\"]\n",
    "        data.loc[index,\"transcript_id\"]=','.join(trans_id)\n",
    "    elif (intron_in_data[\"end\"]==row[\"end\"]).any():\n",
    "        data.loc[index,\"known\"]=\"end\"\n",
    "        trans_id=intron_in_data.loc[intron_in_data[\"end\"]==row[\"end\"],\"transcript_id\"]\n",
    "        data.loc[index,\"transcript_id\"]=','.join(trans_id)\n",
    "    else:\n",
    "        data.loc[index,\"known\"]=\"novel\"\n",
    "        transcript_of_intron=genome.transcript_ids_at_locus(contig=row.chr.replace(\"chr\",\"\"),position=row.end) \n",
    "        mask = protein_intron['transcript_id'].isin(transcript_of_intron)\n",
    "        # Get the transcript IDs that are present\n",
    "        present_transcript_ids = protein_intron.loc[mask, 'transcript_id'].unique()\n",
    "        for transcript in present_transcript_ids:\n",
    "            gene_name=genome.gene_name_of_transcript_id(transcript)\n",
    "            if gene_name!=row[\"genes\"]:\n",
    "                present_transcript_ids=np.delete(present_transcript_ids, np.where(present_transcript_ids == transcript))\n",
    "        if len(present_transcript_ids)>0:\n",
    "            data.loc[index,\"transcript_id\"]=','.join(present_transcript_ids)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"gene_id\"].isin(intron_in_data[\"gene_id\"].unique()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"~/projects/BIO/unmutated_proteomics_junction_all.20230724.tsv\",sep=\"\\t\",index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assembling the novel gene transcript sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=pd.read_csv(\"~/projects/BIO/unmutated_proteomics_junction_all.20230713.tsv\",sep=\"\\t\")\n",
    "data=pd.read_csv(\"~/projects/BIO/unmutated_proteomics_junction_all.20230724.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ls/rachelcw/miniconda3/envs/bio/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3552: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "all_intron=pd.read_csv(\"/data01/private/resources/leafcutter_annot/leafcutter_annot_all_introns.bed.gz\",sep=\"\\t\",header=None,compression=\"gzip\",usecols=[0,1,2,3,4,5,6,8],names=[\"chr\",\"start\",\"end\",\"gene\",\"gene_id\",\"strand\",\"transcript_id\",\"annotation\"])\n",
    "protein_intron=all_intron[all_intron[\"annotation\"]==\"protein_coding\"]\n",
    "data_gene_list=get_gene_list(data['genes'].unique())\n",
    "intron_in_data=protein_intron[protein_intron[\"gene\"].isin(data_gene_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start    74\n",
       "end      66\n",
       "known    62\n",
       "novel     3\n",
       "Name: known, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"known\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ls/rachelcw/miniconda3/envs/bio/lib/python3.7/site-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "# cassette exons #\n",
    "known_intron=data[data[\"known\"]==\"known\"]\n",
    "start_end_intron=[tuple(x) for x in intron_in_data[[\"start\",\"end\"]].values]\n",
    "ce=[tuple(x) for x in known_intron[[\"start\",\"end\"]].values if tuple(x) not in start_end_intron]\n",
    "ce_intron=known_intron.loc[known_intron[[\"start\",\"end\"]].apply(tuple,1).isin(ce)]\n",
    "# ce_intron\n",
    "for index,row in ce_intron.iterrows():\n",
    "    start=intron_in_data.loc[intron_in_data[\"start\"]==row[\"start\"],\"transcript_id\"].values\n",
    "    end=intron_in_data.loc[intron_in_data[\"end\"]==row[\"end\"],\"transcript_id\"].values\n",
    "    # get only the not shared transcript\n",
    "    only_start = [x for x in start if x not in end]  \n",
    "    only_end = [x for x in end if x not in start]\n",
    "    if len(only_start)>0 and len(only_end)>0:\n",
    "        # ce_intron.loc[index,\"transcript_id\"]=','.join(only_start)+'-'+','.join(only_end)\n",
    "        ce_intron.loc[index,\"known\"]=\"two_transcripts\"\n",
    "ce_intron=ce_intron[ce_intron[\"known\"]!=\"two_transcripts\"]\n",
    "# known=[tuple(x) for x in known_intron[[\"start\",\"end\"]].values if tuple(x) in start_end_intron]\n",
    "# only_known_intron=known_intron.loc[known_intron[[\"start\",\"end\"]].apply(tuple,1).isin(known)]\n",
    "# tmp_known_intron=known_intron.loc[(~known_intron[[\"start\",\"end\"]].apply(tuple,1).isin(ce))&(~known_intron[[\"start\",\"end\"]].apply(tuple,1).isin(known))]\n",
    "unknown_intron=data[data[\"known\"]!=\"known\"]\n",
    "novel_intron=pd.concat([unknown_intron,ce_intron], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start    74\n",
       "end      66\n",
       "novel     3\n",
       "Name: known, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novel_intron[\"known\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# novel_intron.to_csv(\"~/projects/BIO/novel_intron.20230711.tsv\",sep=\"\\t\",index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create dictionary: key-transcript id, values- exons-cds location of the transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter_not_cds:  0\n",
      "counter_dup:  44\n"
     ]
    }
   ],
   "source": [
    "transcript_strand_cds=dict()\n",
    "\n",
    "counter_not_cds=0\n",
    "counter_dup=0\n",
    "\n",
    "for index, row in novel_intron.iterrows():\n",
    "    transcript=row[\"transcript_id\"].split(\",\")\n",
    "    chr=row[\"intron\"].split(\":\")[0].replace(\"chr\",\"\")\n",
    "    for t in transcript:\n",
    "        if t not in transcript_strand_cds:\n",
    "            try:\n",
    "                cds=genome.transcript_by_id(t).coding_sequence_position_ranges\n",
    "            except:\n",
    "                counter_not_cds+=1\n",
    "                continue\n",
    "            transcript_strand_cds[t]=[chr,row[\"strand\"],cds]\n",
    "        else:\n",
    "            counter_dup+=1\n",
    "           \n",
    "           \n",
    "print(\"counter_not_cds: \",counter_not_cds)\n",
    "transcript_strand_cds=MappingProxyType(transcript_strand_cds)\n",
    "print(\"counter_dup: \",counter_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcript_exons=dict()\n",
    "# for index, row in novel_intron.iterrows():\n",
    "#     transcript=row[\"transcript_id\"].split(\",\")\n",
    "#     for t in transcript:\n",
    "#         if t not in transcript_exons:\n",
    "#             exons=genome.exon_ids_of_transcript_id(t)\n",
    "#             locus=[genome.locus_of_exon_id(exon).to_tuple() for exon in exons]\n",
    "#             transcript_exons[t]=locus            \n",
    "            \n",
    "# # create the dictionary constant\n",
    "# transcript_exons=MappingProxyType(transcript_exons)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* known **start intron** = end exon1.\n",
    "we want to find out the start of exon2, the closest exon to the end of the intron(start of the next exon) and replace the exon start with the novel intron end\n",
    "\n",
    "* known **end intron** = start exon2.  \n",
    "we want to find out the end of exon1,the closest exon to the start of the intron(end of the previous exon) and replace the exon end with the novel intron start\n",
    "\n",
    "* known **novel intron**.\n",
    "the intron is novel so we want to find the closest exons that the intron is between- the novel start exon2 and the novel end exon1\n",
    "\n",
    "* known **known**.\n",
    "it is casset exon so we want to remove the exon between the start and the end of the intron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem index remove -mutate\n",
    "def get_novel_gene_locus_forward(transcript, start, end, known):\n",
    "    locus=transcript_strand_cds[transcript][2].copy()\n",
    "    start_cds=transcript_strand_cds[transcript][2][0][0]\n",
    "    end_cds=transcript_strand_cds[transcript][2][-1][1]\n",
    "    if known==\"start\":\n",
    "        # known start of the intron -> novel start exon is the end of the intron\n",
    "        if end<start_cds or start>end_cds:\n",
    "            return None #the event is in utr\n",
    "        start_exon=np.array([l[0] for l in locus])\n",
    "        index_exon=np.argmax(start_exon>end)\n",
    "        if start==locus[index_exon][1] & end != locus[index_exon][0]:\n",
    "            index_exon=index_exon+1 # the index refers to the same exon as the known start -> take the next exon\n",
    "        new_exon_locus=tuple([end,locus[index_exon][1]])\n",
    "        locus[index_exon]=new_exon_locus\n",
    "    elif known==\"end\":\n",
    "        # known end of the intron -> novel end exon is the start of the intron\n",
    "        if end<start_cds or start>end_cds:\n",
    "            return None #the event is in utr\n",
    "        end_exon=np.array([l[1] for l in locus])\n",
    "        index_exon=np.argmin(end_exon<start)\n",
    "        if end==locus[index_exon][0] & start != locus[index_exon][1]:\n",
    "            index_exon=index_exon-1 # the index refers to the same exon as the known end -> take the previous exon \n",
    "        new_exon_locus=tuple([locus[index_exon][0],start])\n",
    "        locus[index_exon]=new_exon_locus\n",
    "    elif known==\"novel\":\n",
    "        if end<start_cds or start>end_cds:\n",
    "            return None\n",
    "        index_start=-1\n",
    "        index_end=-1\n",
    "        if end>start_cds and end<end_cds:\n",
    "            # novel start of exon\n",
    "            start_exon=np.array([l[0] for l in locus])\n",
    "            index_start=np.argmax(start_exon>end)\n",
    "            if start==locus[index_start][1] & end != locus[index_exon][0]:\n",
    "                index_start=index_start+1\n",
    "        if start<end_cds and start>start_cds:\n",
    "            # novel end of exon\n",
    "            end_exon=np.array([l[1] for l in locus])\n",
    "            index_end=np.argmin(end_exon<start)\n",
    "            if end==locus[index_end][0] & start != locus[index_end][1]:\n",
    "                index_end=index_end-1\n",
    "        if index_start==-1 and index_end==-1:\n",
    "            return None #the event is in 5' utr\n",
    "        if index_start!=-1:\n",
    "            # novel start exon is the end of the intron\n",
    "            new_start=tuple([end,locus[index_start][1]])\n",
    "            locus[index_start]=new_start\n",
    "        if index_end!=-1:\n",
    "            # novel end exon is the start of the intron\n",
    "            new_end=tuple([locus[index_end][0],start])\n",
    "            locus[index_end]=new_end \n",
    "    elif known==\"known\":\n",
    "        if end<start_cds or start>end_cds:\n",
    "            return None #the event is in utr\n",
    "        if start<start_cds and end>end_cds:\n",
    "            return \"skip cds\" #the event skip on the cds region\n",
    "        if start<start_cds and end>start_cds:\n",
    "            #skip on the start of the cds exon\n",
    "            index=[i for i, tuple in enumerate(locus) if tuple[0]==end]\n",
    "            index_remove=[i for i in range(len(locus)) if index[0]<i]\n",
    "            locus=[locus[i] for i in range(len(locus)) if i not in index_remove]\n",
    "            return locus\n",
    "        index_start=[i for i, tuple in enumerate(locus) if start in tuple] # the first exon\n",
    "        index_end=[i for i, tuple in enumerate(locus) if end in tuple] # the second exon\n",
    "        index_remove=[i for i in range(len(locus)) if index_start[0]<i<index_end[0]]\n",
    "        locus=[locus[i] for i in range(len(locus)) if i not in index_remove]\n",
    "        if known==\"two_transcripts\":\n",
    "            index_start=[i for i, tuple in enumerate(locus) if start in tuple] # the first transcript\n",
    "            index_end=[i for i, tuple in enumerate(locus) if end in tuple] # the second transcript\n",
    "            \n",
    "    return locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ls/rachelcw/miniconda3/envs/bio/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3552: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "five_prime=pd.read_csv(\"/data01/private/resources/leafcutter_annot/leafcutter_annot_fiveprime.bed.gz\", compression='gzip',sep=\"\\t\",header=None,usecols=[0,1,2,3,4,5,6,8],names=[\"chr\",\"0\",\"+1\",\"gene\",\"gene_id\",\"strand\",\"transcript_id\",\"annotation\"])\n",
    "three_prime=pd.read_csv(\"/data01/private/resources/leafcutter_annot/leafcutter_annot_threeprime.bed.gz\", compression='gzip',sep=\"\\t\",header=None,usecols=[0,1,2,3,4,5,6,8],names=[\"chr\",\"0\",\"+1\",\"gene\",\"gene_id\",\"strand\",\"transcript_id\",\"annotation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_novel_gene_locus_reverse(transcript, start, end, known):\n",
    "    # important: in translation the start_cds=end_cds and the end_cds=start_cds  #\n",
    "        locus=transcript_strand_cds[transcript][2].copy()\n",
    "        start_cds=transcript_strand_cds[transcript][2][0][1]\n",
    "        end_cds=transcript_strand_cds[transcript][2][-1][0]\n",
    "        if known == \"start\":\n",
    "            if end<end_cds or start>start_cds:\n",
    "                return None\n",
    "            start_exon=np.array([l[0] for l in locus])\n",
    "            index_exon=np.argmin(start_exon>end)\n",
    "            if start==locus[index_exon][1]:\n",
    "                index_exon=index_exon-1\n",
    "            new_exon_locus=tuple([end,locus[index_exon][1]])\n",
    "            locus[index_exon]=new_exon_locus\n",
    "        elif known == \"end\":\n",
    "            if end<end_cds or start>start_cds:\n",
    "                return None\n",
    "            end_exon=np.array([l[1] for l in locus])\n",
    "            index_exon=np.argmax(end_exon<start)\n",
    "            if end==locus[index_exon][0]:\n",
    "                index_exon=index_exon+1\n",
    "            new_exon_locus=tuple([locus[index_exon][0],start])\n",
    "            locus[index_exon]=new_exon_locus\n",
    "        elif known == \"novel\":\n",
    "            if end<end_cds or start>start_cds:\n",
    "                return None\n",
    "            index_start=-1\n",
    "            index_end=-1\n",
    "            if end<start_cds and end>end_cds:\n",
    "                # novel start of exon\n",
    "                start_exon=np.array([l[0] for l in locus])\n",
    "                index_start=np.argmin(start_exon>end)\n",
    "                if start==locus[index_start][1] & end != locus[index_exon][0]:\n",
    "                    index_start=index_start-1\n",
    "            if start>end_cds and start<start_cds:\n",
    "                # novel end of exon\n",
    "                end_exon=np.array([l[1] for l in locus])\n",
    "                index_end=np.argmax(end_exon<start)\n",
    "                if end==locus[index_end][0] & start != locus[index_end][1]:\n",
    "                    index_end=index_end+1\n",
    "            if index_start==-1 and index_end==-1:\n",
    "                return None  #the event is in utr\n",
    "            if index_start!=-1:\n",
    "                # novel start exon is the end of the intron\n",
    "                new_start=tuple([end,locus[index_start][1]])\n",
    "                locus[index_start]=new_start\n",
    "            if index_end!=-1:\n",
    "                # novel end exon is the start of the intron\n",
    "                new_end=tuple([locus[index_end][0],start])\n",
    "                locus[index_end]=new_end\n",
    "        elif known == \"known\":\n",
    "            if end<end_cds or start>start_cds :\n",
    "                return None #the event is in utr \n",
    "            if start<end_cds and end>start_cds:\n",
    "                return \"skip cds\" #the event skip on the cds region\n",
    "            if start<end_cds and start_cds>end>end_cds:\n",
    "                # the start is out of the cds region and the end is in the cds region\n",
    "                index=[i for i, tuple in enumerate(locus) if tuple[1]==start] # the index of the exon that the start is in\n",
    "                index_remove=[i for i in range(len(locus)) if index[0]<i] # remove all the exons before the end\n",
    "                locus=[locus[i] for i in range(len(locus)) if i not in index_remove]\n",
    "                return locus\n",
    "            index_start=[i for i, tuple in enumerate(locus) if start in tuple]\n",
    "            index_end=[i for i, tuple in enumerate(locus) if end in tuple]\n",
    "            index_remove=[i for i in range(len(locus)) if index_end[0]<i<index_start[0]]\n",
    "            locus=[locus[i] for i in range(len(locus)) if i not in index_remove]\n",
    "        return locus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_gene_id=dict()\n",
    "for index, row in novel_intron.iterrows():\n",
    "    transcript=row[\"transcript_id\"].split(\",\")\n",
    "    for t in transcript:\n",
    "        transcript_gene_id[t]=row[\"gene_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transcript_strand_cds.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n"
     ]
    }
   ],
   "source": [
    "# file known exons(cds) #\n",
    "file_path=\"/data01/private/projects/splicing_cll/results/proteomics/mutated_cll_sf3b1_proteomics.20230725.reference.txt\"\n",
    "rows=0 # num of transcripts\n",
    "with open(file_path,'w') as file:\n",
    "    for t,value in transcript_strand_cds.items():\n",
    "        chr=value[0]\n",
    "        strand=value[1]\n",
    "        cds=value[2]\n",
    "        rows+=1\n",
    "        for loci in cds:\n",
    "            file.write(f'{chr}\\t{loci[0]}\\t{loci[1]}\\t{strand}\\t{t}\\t{transcript_gene_id[t]}\\n')\n",
    "        \n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_start_read(start_cds,locus,strand):\n",
    "    if strand==\"+\":\n",
    "        start_locus=locus[0][0]\n",
    "        if start_locus==start_cds:\n",
    "            return 5 # start read from 5'\n",
    "        else:\n",
    "            return 0 # start read from atg\n",
    "    else: # strand==\"-\"\n",
    "        start_locus=locus[0][1]\n",
    "        if start_locus==start_cds:\n",
    "            return 5 # start read from 5'\n",
    "        else:\n",
    "            return 0 # start read from atg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424\n",
      "0\n",
      "451\n"
     ]
    }
   ],
   "source": [
    "# file novel exons(cds) #\n",
    "file_path=\"/data01/private/projects/splicing_cll/results/proteomics/unmutated_cll_sf3b1_proteomics.20230725.novel.txt\"\n",
    "rows=0 # num of transcripts\n",
    "t_not_cds=0 # num of transcripts not in cds\n",
    "events=0\n",
    "novel_in_utr=open(\"/data01/private/projects/splicing_cll/results/proteomics/unmutated_cll_sf3b1_proteomics.20230725.novel_in_utr.txt\",'w')\n",
    "with open(file_path,'w') as file:\n",
    "    for index, row in novel_intron.iterrows():\n",
    "        transcript=row[\"transcript_id\"].split(\",\")\n",
    "        events+=(len(transcript))\n",
    "        for t in transcript:\n",
    "            if t not in transcript_strand_cds.keys():\n",
    "                t_not_cds+=1\n",
    "                continue\n",
    "            locus=[]\n",
    "            strand=transcript_strand_cds[t][1]\n",
    "            chr=transcript_strand_cds[t][0]\n",
    "            start_cds=-1\n",
    "            end_cds=-1\n",
    "            if strand==\"-\":\n",
    "                start_cds=transcript_strand_cds[t][2][0][1]\n",
    "                end_cds=transcript_strand_cds[t][2][-1][0]\n",
    "                locus=get_novel_gene_locus_reverse(t,row[\"start\"],row[\"end\"],row[\"known\"])\n",
    "            else: # strand==\"+\"\n",
    "                start_cds=transcript_strand_cds[t][2][0][0]\n",
    "                end_cds=transcript_strand_cds[t][2][-1][1]\n",
    "                locus=get_novel_gene_locus_forward(t,row[\"start\"],row[\"end\"],row[\"known\"])\n",
    "            if locus is None:\n",
    "                novel_in_utr.write(f'>{row[\"gene_id\"]}|{t}|{row[\"intron\"]}|\\n')\n",
    "                continue\n",
    "            if locus==\"skip cds\":\n",
    "                print(f'{t} skip cds')\n",
    "                continue\n",
    "            start_from=check_start_read(start_cds,locus,strand)\n",
    "            rows+=1                                      \n",
    "            for loci in locus:\n",
    "                file.write(f'{chr}\\t{loci[0]}\\t{loci[1]}\\t{strand}\\t{t}\\t{transcript_gene_id[t]}\\t{row[\"intron\"]}\\t{start_from}\\n')\n",
    "                # print(f'{chr}\\t{loci[0]}\\t{loci[1]}\\t{strand}\\t{t}\\t{transcript_gene_id[t]}\\t{row[\"intron\"]}\\n') #\n",
    "novel_in_utr.close()\n",
    "print(rows)\n",
    "print(t_not_cds)\n",
    "print(events)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "table=pd.read_csv(\"/data01/private/projects/splicing_cll/results/proteomics/analysis.20230724/results/metadata_cll_sf3b1_proteomics.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ls/rachelcw/miniconda3/envs/bio_sns/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/ls/rachelcw/miniconda3/envs/bio_sns/lib/python3.7/site-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Alternative Splicing', ylabel='Count'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_table=table[table[\"category\"].isin([\"novel_3p\",\"novel_5p\"])]\n",
    "filter_table[\"category\"]=filter_table[\"category\"].str.replace(\"novel_3p\",\"A3SS\").str.replace(\"novel_5p\",\"A5SS\")\n",
    "filter_table.rename(columns={\"category\":\"Alternative Splicing\"},inplace=True)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(data=filter_table[\"Alternative Splicing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmd=all_intron[all_intron[\"annotation\"]==\"nonsense_mediated_decay\"]\n",
    "\n",
    "X=nmd.merge(protein_intron,how=\"inner\",on=\"transcript_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "# Specify the path to your FASTA file\n",
    "known_protein = \"/home/ls/rachelcw/projects/BIO/mutated/mutated_cll_sf3b1_proteomics_known_protein.txt\"\n",
    "novel_protein = \"/home/ls/rachelcw/projects/BIO/mutated/mutated_cll_sf3b1_proteomics_novel_protein.txt\"\n",
    "\n",
    "# Read the sequences from the FASTA file\n",
    "known_sequences = []\n",
    "for record in SeqIO.parse(known_protein, \"fasta\"):\n",
    "    sequence_id = record.id\n",
    "    sequence = record.seq\n",
    "    known_sequences.append((sequence_id, sequence))\n",
    "\n",
    "novel_sequences = []\n",
    "for record in SeqIO.parse(novel_protein, \"fasta\"):\n",
    "    sequence_id = record.id\n",
    "    sequence = record.seq\n",
    "    novel_sequences.append((sequence_id, sequence))\n",
    "\n",
    "# print(known_sequences[0][0])\n",
    "# print(novel_sequences[0][0])\n",
    "# print(f\"Found {len(sequences)} sequences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.pairwise2 import align\n",
    "\n",
    "def calculate_identity(seq1, seq2):\n",
    "    alignments = align.globalxx(seq1, seq2)\n",
    "    # print(alignments)\n",
    "    top_alignment = alignments[0]\n",
    "    alignment_length = top_alignment[4]\n",
    "    matches = top_alignment[2]\n",
    "    identity = (matches / alignment_length) * 100\n",
    "    return np.round(identity,3)\n",
    "\n",
    "# Example protein sequences\n",
    "results=pd.DataFrame(columns=[\"known_id\",\"novel_id\",\"known_seq\",\"novel_seq\",\"identity\"])\n",
    "\n",
    "for known in known_sequences:\n",
    "    for novel in novel_sequences:\n",
    "        if novel[0].startswith(known[0]):\n",
    "            identity = calculate_identity(known[1], novel[1])\n",
    "            results=results.append({\"known_id\":known[0],\"novel_id\":novel[0],\"known_seq\":str(known[1]),\"novel_seq\":str(novel[1]),\"identity\":identity},ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(results[results[\"identity\"]==100])/len(results)\n",
    "identity=results[results[\"identity\"]==100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ls/rachelcw/miniconda3/envs/bio/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/ls/rachelcw/miniconda3/envs/bio/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "identity[\"junction\"]=identity[\"novel_id\"].str.rsplit(\"|\",2,expand=True)[1]\n",
    "identity[\"transcript_id\"]=identity[\"novel_id\"].str.split(\"|\",2,expand=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/ls/rachelcw/projects/BIO/proteomics/100_cases.txt\",'w') as file:\n",
    "    for index, row in identity.iterrows():\n",
    "        file.write(row[\"transcript_id\"]+'\\n')\n",
    "        file.write(row[\"junction\"]+'\\n')\n",
    "        file.write(f'{transcript_strand_cds[row[\"transcript_id\"]][2][-1]}\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGTTTCACGACACGCTGCACGTGAGCGGCGTGTACAATGGGGCTGGCGGGGACACGCACCGGGCCATGCTGCCCAGCCCCCTCAACGTCCGGCTGGAGGCCCCTGCAGGGATGGGGGAGCAGCTGACCGAGACCTTCGCCCTGGACACCAACACAG\n"
     ]
    }
   ],
   "source": [
    "import pyfaidx as fa\n",
    "fasta =fa.Fasta(\"/private1/private/resources/Homo_sapiens_assembly19.fasta\")\n",
    "s=fasta[\"11\"][289920-1:290075].seq\n",
    "# s1=fasta[\"11\"][290919:291113].seq\n",
    "print(s)\n",
    "# print(s1)\n",
    "# print(len(s))\n",
    "# print(s1[0:100])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(72437665, 72438173),\n",
       " (72425197, 72425366),\n",
       " (72424221, 72424288),\n",
       " (72423483, 72423613),\n",
       " (72423241, 72423384),\n",
       " (72422475, 72422544),\n",
       " (72422066, 72422186),\n",
       " (72421430, 72421632),\n",
       " (72420915, 72421021),\n",
       " (72418220, 72418419),\n",
       " (72416850, 72416935),\n",
       " (72415197, 72415379),\n",
       " (72413950, 72414124),\n",
       " (72412694, 72412828),\n",
       " (72410462, 72410597),\n",
       " (72410050, 72410152),\n",
       " (72408956, 72409151),\n",
       " (72408643, 72408694),\n",
       " (72408368, 72408531),\n",
       " (72408028, 72408240),\n",
       " (72407594, 72407699),\n",
       " (72406763, 72406910),\n",
       " (72406587, 72406673),\n",
       " (72406432, 72406500),\n",
       " (72406025, 72406142),\n",
       " (72404737, 72404850),\n",
       " (72404370, 72404515),\n",
       " (72403798, 72403830),\n",
       " (72399500, 72399582),\n",
       " (72398733, 72398783),\n",
       " (72398484, 72398547),\n",
       " (72397087, 72397236),\n",
       " (72396712, 72396726)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# genome.exon_ids_of_transcript_id(\"ENST00000368644.1\")\n",
    "# genome.coding_sequence(\"ENST00000368644.1\")\n",
    "\n",
    "genome.transcript_by_id(\"ENST00000393609.3\").coding_sequence_position_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=genome.transcript_sequence(transcript_id='ENST00000393605.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-c4ee89e0ee24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"intron1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"ENST\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"intron1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"ENST1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ENSG2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"intron1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ENST1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ENSG2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"intron2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"ENST2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ENSG2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "transcript=collections.namedtuple(\"transcript\",['chr', 'start', 'end','strand','gene_id'])\n",
    "transcript=transcript(11,1,2,'-','ENSG')\n",
    "d={\"intron1\":[{\"ENST\":transcript}]}\n",
    "d[\"intron1\"].append({\"ENST1\":[transcript._make([11,1,2,'-','ENSG2'])]})\n",
    "d[\"intron1\"][\"ENST1\"].append(transcript._make([12,1,2,'-','ENSG2']))\n",
    "d[\"intron2\"]={\"ENST2\":transcript._make([11,1,2,'-','ENSG2'])}\n",
    "print(d)\n",
    "for i in d.keys():\n",
    "    print(i)\n",
    "    for j in d[i].keys():\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # option to frame shift- need to change the modulo to the len of the gene until the new locus # #\n",
    "# start_novel_intron=novel_intron[novel_intron[\"novel\"]==\"start\"]\n",
    "# # start_novel_intron[\"frameshift\"]=0\n",
    "# for index, row in start_novel_intron.iterrows():\n",
    "#     transcript=row[\"transcript_id\"].split(\",\")\n",
    "#     t_frame=[]\n",
    "#     for t in transcript:\n",
    "#         start_exon=np.array([l[1] for l in transcript_exons[t]])\n",
    "#         print(row[\"end\"])\n",
    "#         print(start_exon)\n",
    "#         index_exon=np.abs(start_exon-row[\"end\"]).argmin()\n",
    "#         print(index_exon)\n",
    "#         print(\"old\",transcript_exons[t][index_exon])\n",
    "#         new_exon_locus=tuple([transcript_exons[t][index_exon][0],row[\"end\"],transcript_exons[t][index_exon][2],transcript_exons[t][index_exon][3]])\n",
    "#         transcript_exons_updated[t][index_exon]=new_exon_locus\n",
    "#         if (transcript_exons[t][index_exon][2]-transcript_exons[t][index_exon][1]-1)%3!=0:\n",
    "#             print(\"new\",new_exon_locus)\n",
    "#             t_frame.append(t)\n",
    "#     start_novel_intron.loc[index,\"frameshift\"]=','.join(t_frame)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # my trying to create a dictionary of {intron(junction):{t_is:[exons locus]}} ##\n",
    "\n",
    "# intron_transcript=dict()\n",
    "# for index, row in novel_intron.iterrows():\n",
    "#     transcript=row[\"transcript_id\"].split(\",\")\n",
    "#     intron_transcript[row[\"intron\"]] = [{t: transcript_exons[t]} for t in transcript]\n",
    "\n",
    "# start_novel_intron=novel_intron[novel_intron[\"novel\"]==\"start\"]\n",
    "# # start_novel_intron[\"frameshift\"]=0\n",
    "# for index, row in start_novel_intron.iterrows():\n",
    "#     transcript=row[\"transcript_id\"].split(\",\")\n",
    "#     for i,t in enumerate(transcript):\n",
    "#         start_exon=np.array([l[1] for l in transcript_exons[t]])\n",
    "#         index_exon=np.argmax(start_exon>row[\"end\"])\n",
    "#         if row[\"start\"]==transcript_exons[t][index_exon][2]:\n",
    "#             index_exon=index_exon+1\n",
    "#         new_exon_locus=tuple([transcript_exons[t][index_exon][0],row[\"end\"],transcript_exons[t][index_exon][2],transcript_exons[t][index_exon][3]])\n",
    "#         # print(intron_transcript[row[\"intron\"]][i][t][index_exon])\n",
    "#         intron_transcript[row[\"intron\"]][i][t][index_exon]=new_exon_locus\n",
    "#         # print(intron_transcript[row[\"intron\"]][i][t][index_exon])\n",
    "#         # print(t)\n",
    "#         # print(row[\"end\"])\n",
    "#         # print(start_exon)\n",
    "#         # print(index_exon)\n",
    "#         # print(\"old\",transcript_exons[t][index_exon])\n",
    "#         # print(transcript_exons[t])\n",
    "#         # print(\"new\",new_exon_locus)\n",
    "           \n",
    "# end_novel_intron=novel_intron[novel_intron[\"novel\"]==\"end\"]\n",
    "# # start_novel_intron[\"frameshift\"]=0\n",
    "# for index, row in end_novel_intron.iterrows():\n",
    "#     transcript=row[\"transcript_id\"].split(\",\")\n",
    "#     # t_frame=[]\n",
    "#     for i,t in enumerate(transcript):\n",
    "#         end_exon=np.array([l[2] for l in transcript_exons[t]])\n",
    "#         index_exon=np.argmin(end_exon<row[\"start\"])\n",
    "#         if row[\"end\"]==transcript_exons[t][index_exon][1]:\n",
    "#             index_exon=index_exon-1\n",
    "#         new_exon_locus=tuple([transcript_exons[t][index_exon][0],transcript_exons[t][index_exon][1],row[\"start\"],transcript_exons[t][index_exon][3]])\n",
    "#         intron_transcript[row[\"intron\"]][i][t][index_exon]=new_exon_locus\n",
    "#         # print(end_exon<row[\"start\"])\n",
    "#         # print(t)\n",
    "#         # print(row[\"start\"])\n",
    "#         # print(end_exon)\n",
    "#         # print(index_exon)\n",
    "#         # print(\"old\",transcript_exons[t][index_exon])\n",
    "#         # print(transcript_exons[t])\n",
    "#         # print(\"new\",new_exon_locus)\n",
    "\n",
    "# novel_novel_intron=novel_intron[novel_intron[\"novel\"]==\"novel\"]\n",
    "# # start_novel_intron[\"frameshift\"]=0\n",
    "# for index, row in novel_novel_intron.iterrows():\n",
    "#     transcript=row[\"transcript_id\"].split(\",\")\n",
    "#     # t_frame=[]\n",
    "#     for i,t in enumerate(transcript):\n",
    "#         start_exon=np.array([l[1] for l in transcript_exons[t]])\n",
    "#         end_exon=np.array([l[2] for l in transcript_exons[t]])\n",
    "#         index_start=np.argmax(start_exon>row[\"end\"])\n",
    "#         if row[\"start\"]==transcript_exons[t][index_start][2]:\n",
    "#             index_start=index_start+1\n",
    "#         index_end=np.argmin(end_exon<row[\"start\"])\n",
    "#         if row[\"end\"]==transcript_exons[t][index_end][1]:\n",
    "#             index_end=index_end-1\n",
    "#         new_start=tuple([transcript_exons[t][index_start][0],row[\"end\"],transcript_exons[t][index_start][2],transcript_exons[t][index_start][3]])\n",
    "#         new_end=tuple([transcript_exons[t][index_end][0],transcript_exons[t][index_end][1],row[\"start\"],transcript_exons[t][index_end][3]])\n",
    "#         intron_transcript[row[\"intron\"]][i][t][index_start]=new_start\n",
    "#         intron_transcript[row[\"intron\"]][i][t][index_end]=new_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyensembl.search.find_nearest_locus(start, end, loci)\n",
    "# Finds nearest locus (object with method distance_to_interval) to the interval defined by the given start and end positions. Returns the distance to that locus, along with the locus object itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_protein=get_gene_list(novel_intron.loc[novel_intron[\"transcript_id\"]=='',\"genes\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(novel_intron.iloc[191][\"transcript_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PLGLB2'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_intron.loc[protein_intron[\"gene\"].isin(non_protein),\"gene\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome.transcript_ids_at_locus(contig=\"2\",position=88037624)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No results found for query:\n\n            SELECT distinct transcript_id\n            FROM transcript\n            WHERE exon_id = ?\n        \nwith parameters: ['ENSE00000728678.1']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/bio/lib/python3.7/site-packages/pyensembl/common.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (<pyensembl.database.Database object at 0x7fa6e7979f50>, ('distinct', True), ('feature', 'transcript'), ('filter_column', 'exon_id'), ('filter_value', 'ENSE00000728678.1'), ('required', True), ('select_column_names', ('transcript_id',)))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c8f0841f69ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscript_ids_of_exon_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ENSE00000728678.1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/bio/lib/python3.7/site-packages/pyensembl/genome.py\u001b[0m in \u001b[0;36mtranscript_ids_of_exon_id\u001b[0;34m(self, exon_id)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranscript_ids_of_exon_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexon_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query_transcript_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"exon_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexon_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranscript_id_of_protein_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotein_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bio/lib/python3.7/site-packages/pyensembl/genome.py\u001b[0m in \u001b[0;36m_query_transcript_ids\u001b[0;34m(self, property_name, value, feature)\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0mfeature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0mdistinct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             required=True)\n\u001b[0m\u001b[1;32m    975\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bio/lib/python3.7/site-packages/pyensembl/common.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bio/lib/python3.7/site-packages/pyensembl/database.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, select_column_names, filter_column, filter_value, feature, distinct, required)\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mquery_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfilter_value\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         return self.run_sql_query(\n\u001b[0;32m--> 468\u001b[0;31m             sql, required=required, query_params=query_params)\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     def query_one(\n",
      "\u001b[0;32m~/miniconda3/envs/bio/lib/python3.7/site-packages/pyensembl/database.py\u001b[0m in \u001b[0;36mrun_sql_query\u001b[0;34m(self, sql, required, query_params)\u001b[0m\n\u001b[1;32m    439\u001b[0m             raise ValueError(\n\u001b[1;32m    440\u001b[0m                 \"No results found for query:\\n%s\\nwith parameters: %s\" % (\n\u001b[0;32m--> 441\u001b[0;31m                     sql, query_params))\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No results found for query:\n\n            SELECT distinct transcript_id\n            FROM transcript\n            WHERE exon_id = ?\n        \nwith parameters: ['ENSE00000728678.1']"
     ]
    }
   ],
   "source": [
    "genome.transcript_ids_of_exon_id('ENSE00000728678.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENST00000331244.5', 'ENST00000368644.1', 'ENST00000481034.1']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome.transcript_ids_at_locus(contig=\"10\",position=131960844,end=131964771,strand=\"+\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio_sns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
